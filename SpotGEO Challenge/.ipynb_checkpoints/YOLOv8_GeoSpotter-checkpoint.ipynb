{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\gpu\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" # Esto sirve para que no pete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.42  Python-3.9.13 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1060, 6144MiB)\n",
      "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=D:/TFM/TFM-DATOS/data.yaml, epochs=20, patience=50, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, min_memory=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, split=val, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs\\detect\\train7\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.Detect                [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\TFM\\TFM-DATOS\\train\\1000.cache... 76800 images, 19548 backgrounds, 0 corrupt: 100%|██████████| 76800/76800 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\TFM\\TFM-DATOS\\train\\1000.cache... 76800 images, 19548 backgrounds, 0 corrupt: 100%|██████████| 76800/76800 [00:00<?, ?it/s]\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train7\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/20      5.38G      2.533      2.556     0.8485         86        640: 100%|██████████| 2400/2400 [37:56<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1200 [00:00<?, ?it/s]WARNING  NMS time limit 3.700s exceeded\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1200/1200 [18:59<00:00,  1.05it/s] \n",
      "                   all      76800     134328      0.768       0.58      0.657      0.273\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/20       5.6G      2.156      1.631     0.8172         72        640: 100%|██████████| 2400/2400 [35:35<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1200/1200 [17:45<00:00,  1.13it/s]\n",
      "                   all      76800     134328      0.826      0.674      0.752      0.347\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/20      4.88G       2.08      1.569     0.8132         83        640: 100%|██████████| 2400/2400 [34:54<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1200/1200 [17:44<00:00,  1.13it/s]\n",
      "                   all      76800     134328      0.801      0.652      0.723      0.336\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/20      4.93G      2.022      1.507      0.809         88        640: 100%|██████████| 2400/2400 [5:41:08<00:00,  8.53s/it]      \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1200/1200 [17:50<00:00,  1.12it/s]\n",
      "                   all      76800     134328       0.85      0.703      0.785      0.377\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/20      4.93G      1.956      1.432     0.8048         84        640: 100%|██████████| 2400/2400 [41:31<00:00,  1.04s/it]  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1200/1200 [17:26<00:00,  1.15it/s]\n",
      "                   all      76800     134328      0.842       0.73      0.801      0.389\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/20      4.93G      1.917      1.384     0.8005         69        640: 100%|██████████| 2400/2400 [34:32<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1200/1200 [17:28<00:00,  1.14it/s]\n",
      "                   all      76800     134328      0.848       0.75      0.816      0.401\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/20      4.93G      1.889      1.353      0.798         80        640: 100%|██████████| 2400/2400 [34:37<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1200/1200 [17:30<00:00,  1.14it/s]\n",
      "                   all      76800     134328      0.845      0.763      0.824      0.409\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/20      4.93G      1.856      1.316     0.7969         84        640: 100%|██████████| 2400/2400 [36:05<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1200/1200 [18:21<00:00,  1.09it/s]\n",
      "                   all      76800     134328       0.84      0.765      0.827      0.422\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/20      4.93G      1.823      1.292     0.7946         93        640: 100%|██████████| 2400/2400 [34:39<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1200/1200 [17:38<00:00,  1.13it/s]\n",
      "                   all      76800     134328      0.839      0.773      0.834      0.434\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/20      4.93G      1.797      1.268     0.7939        117        640: 100%|██████████| 2400/2400 [36:42<00:00,  1.09it/s] \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1200/1200 [17:39<00:00,  1.13it/s]\n",
      "                   all      76800     134328      0.837      0.781      0.839      0.443\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/20      4.93G      1.746      1.207      0.797         40        640: 100%|██████████| 2400/2400 [33:51<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1200/1200 [17:29<00:00,  1.14it/s]\n",
      "                   all      76800     134328      0.844      0.781      0.842      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/20      4.93G      1.718      1.184     0.7959         57        640: 100%|██████████| 2400/2400 [33:49<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1200/1200 [17:25<00:00,  1.15it/s]\n",
      "                   all      76800     134328      0.844      0.784      0.845      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/20      4.93G      1.688      1.155     0.7946         65        640: 100%|██████████| 2400/2400 [33:50<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1200/1200 [17:32<00:00,  1.14it/s]\n",
      "                   all      76800     134328      0.843      0.787      0.846      0.461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/20      4.93G      1.656      1.131     0.7921         65        640: 100%|██████████| 2400/2400 [33:55<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1200/1200 [17:58<00:00,  1.11it/s]\n",
      "                   all      76800     134328      0.841      0.788      0.847      0.465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/20      4.93G      1.626        1.1     0.7912         56        640: 100%|██████████| 2400/2400 [33:57<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1200/1200 [17:25<00:00,  1.15it/s]\n",
      "                   all      76800     134328      0.843      0.788      0.849      0.469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/20      4.93G       1.59      1.068       0.79         54        640: 100%|██████████| 2400/2400 [33:56<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1200/1200 [17:33<00:00,  1.14it/s]\n",
      "                   all      76800     134328      0.845      0.788      0.851      0.473\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/20      4.93G      1.554      1.046     0.7892         59        640: 100%|██████████| 2400/2400 [34:01<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1200/1200 [17:51<00:00,  1.12it/s]\n",
      "                   all      76800     134328      0.848       0.79      0.854      0.477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/20      4.93G      1.516       1.01     0.7872         55        640: 100%|██████████| 2400/2400 [34:04<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1200/1200 [18:22<00:00,  1.09it/s]\n",
      "                   all      76800     134328       0.85      0.791      0.856      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/20      4.93G      1.468     0.9766     0.7855         35        640: 100%|██████████| 2400/2400 [34:05<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1200/1200 [17:44<00:00,  1.13it/s]\n",
      "                   all      76800     134328      0.853      0.792      0.858      0.486\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/20      4.93G      1.426     0.9401     0.7833         45        640: 100%|██████████| 2400/2400 [33:56<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1200/1200 [18:52<00:00,  1.06it/s]\n",
      "                   all      76800     134328      0.856      0.794      0.861      0.491\n",
      "\n",
      "20 epochs completed in 23.310 hours.\n",
      "Optimizer stripped from runs\\detect\\train7\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train7\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train7\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.42  Python-3.9.13 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1060, 6144MiB)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1200/1200 [18:26<00:00,  1.08it/s]\n",
      "                   all      76800     134328      0.856      0.794      0.861      0.491\n",
      "Speed: 0.2ms preprocess, 4.2ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "model.train(data=\"D:/TFM/TFM-DATOS/data.yaml\", epochs=50, batch=32, optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"/home/marc/Descargas/memoria-scripts/TFM/runs/detect/0.75/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def predictImage(path,wantToPrint):\n",
    "    \n",
    "    result = model(path + \".png\")\n",
    "\n",
    "    # if wantToPrint:\n",
    "    #     res_plotted = result[0].plot()\n",
    "    #     plt.imshow(res_plotted)\n",
    "    #     plt.show()\n",
    "    \n",
    "    boxes = result[0].boxes\n",
    "    \n",
    "    listaBoxes = []\n",
    "\n",
    "    for box in boxes:\n",
    "        lista = box.xywhn[0].tolist()\n",
    "        listaBoxes.append([round(lista[0], 2), round(lista[1], 2)])\n",
    "        if wantToPrint:\n",
    "            print(f'{lista[0]},{lista[1]},{lista[2]},{lista[3]}')\n",
    "\n",
    "    # img = cv2.imread(path + \".png\")\n",
    "\n",
    "    # darknet_path = path + \".txt\"\n",
    "\n",
    "    # height_images = img.shape[0]\n",
    "    # width_images = img.shape[1]\n",
    "\n",
    "    # listaBoxesDarknet = []\n",
    "\n",
    "    # with open(darknet_path, 'r') as f:\n",
    "    #     for i, line in enumerate(f):\n",
    "    #         # Obtener las coordenadas del objeto\n",
    "    #         class_index, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "\n",
    "    #         if wantToPrint:\n",
    "    #             xmin = int((x_center - width/2) * width_images)\n",
    "    #             ymin = int((y_center - height/2) * height_images)\n",
    "    #             xmax = int((x_center + width/2) * width_images)\n",
    "    #             ymax = int((y_center + height/2) * height_images)\n",
    "\n",
    "    #             cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (255,0,0), thickness=2)\n",
    "\n",
    "    #             print(f'{x_center},{y_center},{width},{height}')\n",
    "            \n",
    "    #         listaBoxesDarknet.append([round(x_center, 2),round(y_center, 2)])\n",
    "\n",
    "    # if wantToPrint:\n",
    "    #     plt.imshow(img)\n",
    "    #     plt.show()\n",
    "\n",
    "    if not wantToPrint:\n",
    "        return listaBoxes#, listaBoxesDarknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 E:\\Universidad\\TFM-DATOS\\test\\10\\5.png: 480x640 75.3ms\n",
      "Speed: 1.0ms pre-process, 75.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
      "type: <class 'torch.Tensor'>\n",
      "shape: torch.Size([0, 6])\n",
      "dtype: torch.float32\n",
      " + tensor([], size=(0, 6))]\n",
      "tensor([], size=(0, 6))\n"
     ]
    }
   ],
   "source": [
    "path = \"E:/Universidad/TFM-DATOS/test/10/5\"\n",
    "lista = predictImage(path,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\1.png: 480x640 3 satellites, 99.6ms\n",
      "Speed: 244.2ms preprocess, 99.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\1_180.png: 480x640 3 satellites, 95.6ms\n",
      "Speed: 16.7ms preprocess, 95.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\1_180_flipH.png: 480x640 3 satellites, 67.2ms\n",
      "Speed: 8.0ms preprocess, 67.2ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\1_180_flipV.png: 480x640 3 satellites, 60.5ms\n",
      "Speed: 0.0ms preprocess, 60.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\1_270.png: 640x480 3 satellites, 56.2ms\n",
      "Speed: 8.0ms preprocess, 56.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\1_270_flipH.png: 640x480 3 satellites, 15.9ms\n",
      "Speed: 0.0ms preprocess, 15.9ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\1_270_flipV.png: 640x480 3 satellites, 16.1ms\n",
      "Speed: 0.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\1_90.png: 640x480 3 satellites, 18.7ms\n",
      "Speed: 0.0ms preprocess, 18.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\1_90_flipH.png: 640x480 3 satellites, 24.0ms\n",
      "Speed: 0.0ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\1_90_flipV.png: 640x480 3 satellites, 22.5ms\n",
      "Speed: 0.0ms preprocess, 22.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\1_flipH.png: 480x640 3 satellites, 23.9ms\n",
      "Speed: 0.0ms preprocess, 23.9ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\1_flipV.png: 480x640 3 satellites, 22.1ms\n",
      "Speed: 0.0ms preprocess, 22.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\2.png: 480x640 3 satellites, 16.0ms\n",
      "Speed: 0.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\2_180.png: 480x640 3 satellites, 21.8ms\n",
      "Speed: 0.0ms preprocess, 21.8ms inference, 9.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\2_180_flipH.png: 480x640 3 satellites, 15.0ms\n",
      "Speed: 1.1ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\2_180_flipV.png: 480x640 3 satellites, 14.5ms\n",
      "Speed: 0.0ms preprocess, 14.5ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\2_270.png: 640x480 3 satellites, 16.0ms\n",
      "Speed: 0.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\2_270_flipH.png: 640x480 3 satellites, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\2_270_flipV.png: 640x480 3 satellites, 20.3ms\n",
      "Speed: 0.0ms preprocess, 20.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\2_90.png: 640x480 3 satellites, 9.3ms\n",
      "Speed: 0.0ms preprocess, 9.3ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\2_90_flipH.png: 640x480 3 satellites, 18.3ms\n",
      "Speed: 0.0ms preprocess, 18.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\2_90_flipV.png: 640x480 3 satellites, 16.0ms\n",
      "Speed: 0.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\2_flipH.png: 480x640 3 satellites, 16.0ms\n",
      "Speed: 0.0ms preprocess, 16.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\2_flipV.png: 480x640 3 satellites, 17.0ms\n",
      "Speed: 0.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\3.png: 480x640 3 satellites, 16.0ms\n",
      "Speed: 0.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\3_180.png: 480x640 2 satellites, 16.0ms\n",
      "Speed: 0.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\3_180_flipH.png: 480x640 3 satellites, 16.0ms\n",
      "Speed: 0.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\3_180_flipV.png: 480x640 3 satellites, 16.0ms\n",
      "Speed: 0.0ms preprocess, 16.0ms inference, 8.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\3_270.png: 640x480 3 satellites, 16.3ms\n",
      "Speed: 8.0ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\3_270_flipH.png: 640x480 2 satellites, 13.2ms\n",
      "Speed: 0.0ms preprocess, 13.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\3_270_flipV.png: 640x480 3 satellites, 14.4ms\n",
      "Speed: 0.0ms preprocess, 14.4ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\3_90.png: 640x480 3 satellites, 16.4ms\n",
      "Speed: 0.0ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\3_90_flipH.png: 640x480 3 satellites, 16.4ms\n",
      "Speed: 0.0ms preprocess, 16.4ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\3_90_flipV.png: 640x480 2 satellites, 28.8ms\n",
      "Speed: 0.0ms preprocess, 28.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\3_flipH.png: 480x640 3 satellites, 16.0ms\n",
      "Speed: 0.0ms preprocess, 16.0ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\3_flipV.png: 480x640 3 satellites, 8.0ms\n",
      "Speed: 2.6ms preprocess, 8.0ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\4.png: 480x640 2 satellites, 11.5ms\n",
      "Speed: 0.0ms preprocess, 11.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\4_180.png: 480x640 2 satellites, 13.0ms\n",
      "Speed: 0.0ms preprocess, 13.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\4_180_flipH.png: 480x640 2 satellites, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 13.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\4_180_flipV.png: 480x640 2 satellites, 15.3ms\n",
      "Speed: 0.0ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\4_270.png: 640x480 2 satellites, 16.3ms\n",
      "Speed: 0.0ms preprocess, 16.3ms inference, 15.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\4_270_flipH.png: 640x480 2 satellites, 25.3ms\n",
      "Speed: 0.0ms preprocess, 25.3ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\4_270_flipV.png: 640x480 2 satellites, 4.6ms\n",
      "Speed: 0.0ms preprocess, 4.6ms inference, 13.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\4_90.png: 640x480 2 satellites, 16.4ms\n",
      "Speed: 0.0ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\4_90_flipH.png: 640x480 2 satellites, 16.1ms\n",
      "Speed: 0.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\4_90_flipV.png: 640x480 2 satellites, 18.6ms\n",
      "Speed: 0.0ms preprocess, 18.6ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\4_flipH.png: 480x640 2 satellites, 20.2ms\n",
      "Speed: 0.0ms preprocess, 20.2ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\4_flipV.png: 480x640 2 satellites, 1.6ms\n",
      "Speed: 0.0ms preprocess, 1.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\5.png: 480x640 4 satellites, 16.0ms\n",
      "Speed: 0.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\5_180.png: 480x640 3 satellites, 11.5ms\n",
      "Speed: 0.0ms preprocess, 11.5ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\5_180_flipH.png: 480x640 3 satellites, 16.0ms\n",
      "Speed: 0.0ms preprocess, 16.0ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\5_180_flipV.png: 480x640 4 satellites, 16.0ms\n",
      "Speed: 0.0ms preprocess, 16.0ms inference, 8.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\5_270.png: 640x480 3 satellites, 16.1ms\n",
      "Speed: 0.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\5_270_flipH.png: 640x480 4 satellites, 16.0ms\n",
      "Speed: 0.0ms preprocess, 16.0ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\5_270_flipV.png: 640x480 4 satellites, 19.1ms\n",
      "Speed: 0.0ms preprocess, 19.1ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\5_90.png: 640x480 3 satellites, 23.7ms\n",
      "Speed: 0.0ms preprocess, 23.7ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\5_90_flipH.png: 640x480 4 satellites, 21.6ms\n",
      "Speed: 0.0ms preprocess, 21.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\5_90_flipV.png: 640x480 4 satellites, 16.1ms\n",
      "Speed: 0.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\5_flipH.png: 480x640 4 satellites, 16.0ms\n",
      "Speed: 0.0ms preprocess, 16.0ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\TFM\\TFM-DATOS\\train\\1\\5_flipV.png: 480x640 3 satellites, 19.0ms\n",
      "Speed: 0.0ms preprocess, 19.0ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "index_orig, index_90, index_180, index_270, index_fV, index_fH, index_fV_90, index_fV_180, index_fV_270, index_fH_90, index_fH_180, index_fH_270 = 0,1,2,3,4,5,6,7,8,9,10,11\n",
    "\n",
    "def getCorrectIndex(fileName):\n",
    "  index = index_orig\n",
    "  if \"\" in fileName:\n",
    "    index = index_orig\n",
    "  if \"_90\" in fileName:\n",
    "    index = index_90\n",
    "  if \"_180\" in fileName:\n",
    "    index = index_180\n",
    "  if \"_270\" in fileName:\n",
    "    index = index_270\n",
    "  if \"_flipV\" in fileName:\n",
    "    index = index_fV\n",
    "  if \"_flipH\" in fileName:\n",
    "    index = index_fH\n",
    "  if \"_90_flipV\" in fileName:\n",
    "    index = index_fV_90\n",
    "  if \"_180_flipV\" in fileName:\n",
    "    index = index_fV_180\n",
    "  if \"_270_flipV\" in fileName:\n",
    "    index = index_fV_270\n",
    "  if \"_90_flipH\" in fileName:\n",
    "    index = index_fH_90\n",
    "  if \"_180_flipH\" in fileName:\n",
    "    index = index_fH_180\n",
    "  if \"_270_flipH\" in fileName:\n",
    "    index = index_fH_270\n",
    "  return index\n",
    "\n",
    "\n",
    "image_folder = \"C:/TFM/TFM-DATOS/train/\"\n",
    "\n",
    "listaSecuencias = []\n",
    "\n",
    "folder_path = \"C:/TFM/TFM-DATOS/train/1/\"\n",
    "\n",
    "# for folder in os.listdir(image_folder):\n",
    "#   folder_path = os.path.join(image_folder, folder)\n",
    "if os.path.isdir(folder_path):\n",
    "  listaFolder = [[],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "  for file in os.listdir(folder_path):\n",
    "    extension = file.split('.')\n",
    "    if extension[1] == \"png\":\n",
    "      imagePath = os.path.join(folder_path, extension[0])\n",
    "\n",
    "      result = model(imagePath + \".png\")\n",
    "\n",
    "      boxes = result[0].boxes\n",
    "\n",
    "      listaBoxes = []\n",
    "\n",
    "      for box in boxes:\n",
    "          lista = box.xywhn[0].tolist()\n",
    "          listaBoxes.append([lista[0], lista[1]])\n",
    "      \n",
    "      index_selected = getCorrectIndex(extension[0])\n",
    "      listaFolder[index_selected].append([extension[0].split('_')[0],listaBoxes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22109374403953552, 0.2697916626930237], [0.7671874761581421, 0.4635416567325592], [0.785937488079071, 0.4947916567325592]]\n",
      "[[0.2632812559604645, 0.22499999403953552], [0.811718761920929, 0.4156250059604645], [0.8304687738418579, 0.4468750059604645]]\n",
      "[[0.30546873807907104, 0.17916665971279144], [0.8539062738418579, 0.36770832538604736], [0.8726562261581421, 0.3968749940395355]]\n",
      "[[0.897656261920929, 0.31979167461395264], [0.9164062738418579, 0.35104167461395264]]\n",
      "[[0.390625, 0.0885416641831398], [0.9117187261581421, 0.25208333134651184], [0.942187488079071, 0.2708333432674408], [0.960156261920929, 0.3031249940395355]]\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "for i in listaFolder[0]:\n",
    "    print(sorted(i[1], key=itemgetter(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"C:/Users/Marc/Desktop/memoria-scripts/TFM/runs/detect/0.75/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Marc\\Desktop\\memoria-scripts\\train-memoria-ejemplos\\1\\1.png: 480x640 3 satellites, 74.6ms\n",
      "Speed: 1.0ms pre-process, 74.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def predictImage(path,wantToPrint):\n",
    "    \n",
    "    width_images = 640\n",
    "    height_images = 480\n",
    "\n",
    "    result = model(path + \".png\")\n",
    "    \n",
    "    if wantToPrint:\n",
    "        res_plotted = result[0].plot()\n",
    "        plt.imshow(res_plotted)\n",
    "        plt.show()\n",
    "\n",
    "    boxes = result[0].boxes\n",
    "\n",
    "    listaBoxes = []\n",
    "\n",
    "    for box in boxes:\n",
    "        lista = box.xywhn[0].tolist()\n",
    "        xmin = int((x_center - width/2) * width_images)\n",
    "        ymin = int((y_center - height/2) * height_images)\n",
    "        xmax = int((x_center + width/2) * width_images)\n",
    "        ymax = int((y_center + height/2) * height_images)\n",
    "        listaBoxes.append([round(lista[0], 2), round(lista[1], 2)])\n",
    "        if wantToPrint:\n",
    "            print(f'{lista[0]},{lista[1]},{lista[2]},{lista[3]}')\n",
    "    \n",
    "    darknet_path = path + \".txt\"\n",
    "    \n",
    "    listaDarknet = []\n",
    "    \n",
    "    with open(darknet_path, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            class_index, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "            \n",
    "            listaDarknet.append([float(\"{:.2f}\".format(x_center)), float(\"{:.2f}\".format(y_center))])\n",
    "\n",
    "    # img = cv2.imread(path + \".png\")\n",
    "\n",
    "    # darknet_path = path + \".txt\"\n",
    "\n",
    "    # height_images = img.shape[0]\n",
    "    # width_images = img.shape[1]\n",
    "\n",
    "    # listaBoxesDarknet = []\n",
    "\n",
    "    # with open(darknet_path, 'r') as f:\n",
    "    #     for i, line in enumerate(f):\n",
    "    #         # Obtener las coordenadas del objeto\n",
    "    #         class_index, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "\n",
    "    #         if wantToPrint:\n",
    "    #             xmin = int((x_center - width/2) * width_images)\n",
    "    #             ymin = int((y_center - height/2) * height_images)\n",
    "    #             xmax = int((x_center + width/2) * width_images)\n",
    "    #             ymax = int((y_center + height/2) * height_images)\n",
    "\n",
    "    #             cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (255,0,0), thickness=2)\n",
    "\n",
    "    #             print(f'{x_center},{y_center},{width},{height}')\n",
    "            \n",
    "    #         listaBoxesDarknet.append([round(x_center, 2),round(y_center, 2)])\n",
    "\n",
    "    # if wantToPrint:\n",
    "    #     plt.imshow(img)\n",
    "    #     plt.show()\n",
    "    listaBoxes.sort()\n",
    "    listaDarknet.sort()\n",
    "    return listaBoxes, listaDarknet\n",
    "\n",
    "path = \"C:/Users/Marc/Desktop/memoria-scripts/train-memoria-ejemplos/1/1\"\n",
    "\n",
    "listaBoxes, listaDarknet = predictImage(path,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22, 0.27], [0.77, 0.46], [0.79, 0.49]]\n",
      "[[0.22, 0.27], [0.77, 0.46], [0.79, 0.49]]\n"
     ]
    }
   ],
   "source": [
    "print(listaBoxes)\n",
    "print(listaDarknet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(esta_en_recta((0.22, 0.27),(0.26, 0.22),(0.31, 0.18), tolerancia=0.3,zona=0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def esta_en_recta(punto1, punto2, punto3, tolerancia=0.01):\n",
    "    x1, y1 = punto1\n",
    "    x2, y2 = punto2\n",
    "    x3, y3 = punto3\n",
    "\n",
    "    # Calcular pendientes entre los dos puntos conocidos y entre uno de ellos y el tercer punto\n",
    "    pendiente1 = (y2 - y1) / (x2 - x1) if (x2 - x1) != 0 else float('inf')\n",
    "    pendiente2 = (y3 - y1) / (x3 - x1) if (x3 - x1) != 0 else float('inf')\n",
    "\n",
    "    # Verificar si las pendientes son iguales dentro de una tolerancia\n",
    "    if abs(pendiente1 - pendiente2) < tolerancia:\n",
    "        x_tend = x1 - x2\n",
    "        y_tend = y1 - y2\n",
    "\n",
    "        sigue_x = (x_tend > 0 and (x2 - x3) > 0) or (x_tend < 0 and (x2 - x3) < 0) or (x_tend == 0 and (x2 - x3) == 0)\n",
    "        sigue_y = (y_tend > 0 and (y2 - y3) > 0) or (y_tend < 0 and (y2 - y3) < 0) or (y_tend == 0 and (y2 - y3) == 0)\n",
    "\n",
    "        return sigue_x and sigue_y\n",
    "\n",
    "def calculate_distance(point1, point2):\n",
    "    return math.dist(point1[1],point2[1]) / (point1[0] - point2[0])\n",
    "\n",
    "def check_if_tupla_in_list(lista_tuplas, tupla, lista_final):\n",
    "    for i in lista_tuplas:\n",
    "        for j in i:\n",
    "            if j == tupla:\n",
    "                return True\n",
    "    for i in lista_final:\n",
    "        for j in i:\n",
    "            if j == tupla:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_lines_of_sequence(primera_sequencia, segunda_sequencia, sequences, tolerancia, tol_dist):\n",
    "\n",
    "    lista_final = []\n",
    "\n",
    "    for i_prim in primera_sequencia:\n",
    "\n",
    "        lista_ordenada_por_distancia = []\n",
    "\n",
    "        for i,tupla in enumerate(segunda_sequencia):\n",
    "            seq1, seq2 = i_prim,segunda_sequencia[i]\n",
    "            tupla_nueva = [(sequences.index(primera_sequencia) + 1, seq1), (sequences.index(segunda_sequencia) + 1, seq2)]\n",
    "            lista_ordenada_por_distancia.append(tupla_nueva)\n",
    "        \n",
    "        for lista in lista_ordenada_por_distancia:\n",
    "            for index, seq in enumerate(sequences):\n",
    "                if seq != primera_sequencia and seq != segunda_sequencia:\n",
    "                    menor = None\n",
    "                    menor_tupla = None\n",
    "                    for tupla in seq:\n",
    "                        if not check_if_tupla_in_list(lista_ordenada_por_distancia, (index + 1, tupla), lista_final):\n",
    "                            dist_ant = calculate_distance(lista[-2], lista[-1])\n",
    "                            \n",
    "                            dist = calculate_distance(lista[-1], (index + 1, tupla))\n",
    "\n",
    "                            if lista[-2][0] > index + 1:\n",
    "                                point1 = tupla\n",
    "                                point2 = lista[-2][1]\n",
    "                                point3 = lista[-1][1]\n",
    "                            elif lista[-1][0] > index + 1:\n",
    "                                point1 = lista[-2][1]\n",
    "                                point2 = tupla\n",
    "                                point3 = lista[-1][1]\n",
    "                            else:\n",
    "                                point1 = lista[-2][1]\n",
    "                                point2 = lista[-1][1]\n",
    "                                point3 = tupla\n",
    "\n",
    "                            if esta_en_recta(point1, point2, point3, tolerancia) and ((abs(dist) - abs(dist_ant)) < tol_dist and (abs(dist) - abs(dist_ant)) > -tol_dist):\n",
    "                                if menor == None or dist < menor:\n",
    "                                    menor = dist\n",
    "                                    menor_tupla = tupla\n",
    "                    \n",
    "                    if menor != None and menor_tupla != None:\n",
    "                        # print(f\"SE INSERTA: {(index + 1, menor_tupla)}\")\n",
    "                        lista.insert(index, (index + 1, menor_tupla))\n",
    "                        lista.sort()\n",
    "\n",
    "        max = None\n",
    "        for i in lista_ordenada_por_distancia:\n",
    "            if max == None:\n",
    "                max = i\n",
    "            elif len(i) > len(max):\n",
    "                max = i\n",
    "        if len(max) > 2:\n",
    "            lista_final.append(max)\n",
    "    \n",
    "    return lista_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_tupla_in_list_total(lista_total, lista):\n",
    "    for i in lista:\n",
    "        for j in lista_total:\n",
    "            for x in j:\n",
    "                if x == i:\n",
    "                    return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_objects(sequences, tolerancia, tol_dist):\n",
    "\n",
    "    lista_total = []\n",
    "\n",
    "    for i in range(len(sequences)-1):\n",
    "        lista_result = search_lines_of_sequence(sequences[i], sequences[i + 1], sequences, tolerancia, tol_dist)\n",
    "        \n",
    "        for j in lista_result:\n",
    "            if j not in lista_total and not check_if_tupla_in_list_total(lista_total, j):\n",
    "                lista_total.append(j)\n",
    "\n",
    "    return lista_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_points(start_point, end_point, num_points):\n",
    "    # Calcula la distancia entre los puntos\n",
    "    dx = (end_point[0] - start_point[0]) / (num_points + 1)\n",
    "    dy = (end_point[1] - start_point[1]) / (num_points + 1)\n",
    "\n",
    "    # Genera los puntos intermedios\n",
    "    points = []\n",
    "    for i in range(num_points):\n",
    "        x = start_point[0] + dx * (i + 1)\n",
    "        y = start_point[1] + dy * (i + 1)\n",
    "        \n",
    "        points.append((float(\"{:.2f}\".format(x)), float(\"{:.2f}\".format(y))))\n",
    "\n",
    "    return points\n",
    "\n",
    "def generate_next_point(prev_point, current_point):\n",
    "    # Calcula la distancia entre los puntos\n",
    "    dx = current_point[0] - prev_point[0]\n",
    "    dy = current_point[1] - prev_point[1]\n",
    "\n",
    "    # Calcula las coordenadas del siguiente punto\n",
    "    next_x = current_point[0] + dx\n",
    "    next_y = current_point[1] + dy\n",
    "\n",
    "    return [(float(\"{:.2f}\".format(next_x)), float(\"{:.2f}\".format(next_y)))]\n",
    "\n",
    "def generate_before_point(prev_point, current_point):\n",
    "    # Calcula la distancia entre los puntos\n",
    "    dx = prev_point[0] - current_point[0]\n",
    "    dy = prev_point[1] - current_point[1]\n",
    "\n",
    "    # Calcula las coordenadas del siguiente punto\n",
    "    next_x = prev_point[0] + dx\n",
    "    next_y = prev_point[1] + dy\n",
    "\n",
    "    return [(float(\"{:.2f}\".format(next_x)), float(\"{:.2f}\".format(next_y)))]\n",
    "\n",
    "def state_of_point(index_list, index):\n",
    "    menor = None\n",
    "    mayor = None\n",
    "    for i in index_list:\n",
    "        if i < index:\n",
    "            if menor == None:\n",
    "                menor = i\n",
    "            else:\n",
    "                if i > menor:\n",
    "                    menor = i\n",
    "        if i > index:\n",
    "            if mayor == None:\n",
    "                mayor = i\n",
    "            else:\n",
    "                if i < mayor:\n",
    "                    mayor = i\n",
    "    \n",
    "    return menor, mayor\n",
    "\n",
    "def complete_list(points_list):\n",
    "    # Genera los puntos que faltan\n",
    "    completed_list = points_list\n",
    "\n",
    "    index_list = [i[0] for i in completed_list]\n",
    "\n",
    "    for i in range(1,6):\n",
    "        if i not in index_list:\n",
    "            menor, mayor = state_of_point(index_list, i)\n",
    "            points = None\n",
    "            if menor != None and mayor != None:\n",
    "                points = interpolate_points(points_list[index_list.index(menor)][1], points_list[index_list.index(mayor)][1], (mayor - menor) - 1)\n",
    "            elif menor != None:\n",
    "                if index_list.index(menor) - 1 >= 0:\n",
    "                    prev = points_list[index_list.index(menor) - 1]\n",
    "                cur = points_list[index_list.index(menor)]\n",
    "                if prev != None and cur != None and cur[0] - prev[0] == 1:\n",
    "                    points = generate_next_point(prev[1], cur[1])\n",
    "            elif mayor != None:\n",
    "                prev = points_list[index_list.index(mayor)]\n",
    "                if index_list.index(mayor) + 1 < len(points_list):\n",
    "                    cur = points_list[index_list.index(mayor) + 1]\n",
    "                if prev != None and cur != None and cur[0] - prev[0] == 1:\n",
    "                    points = generate_before_point(prev[1], cur[1])\n",
    "            \n",
    "            if points != None:\n",
    "                suma = 1    \n",
    "                for j in points:\n",
    "                    if menor == None:\n",
    "                        menor = 0\n",
    "                    completed_list.append((menor + suma, j))\n",
    "                    suma += 1\n",
    "                completed_list.sort()\n",
    "                index_list = [i[0] for i in completed_list]\n",
    "\n",
    "    return completed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_result(sequences, tolerancia, tol_dist):\n",
    "    lista = search_for_objects(sequences, tolerancia, tol_dist)\n",
    "    \n",
    "    for i in lista:\n",
    "        acabado = False\n",
    "        while not acabado:\n",
    "            complete_list(i)\n",
    "            if len(i) == 5:\n",
    "                acabado = True\n",
    "\n",
    "    # for index, i in enumerate(lista):\n",
    "    #     print(f\"Linea {index}: {i}\")\n",
    "\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicts_and_reals(path):\n",
    "\n",
    "    predicts = []\n",
    "    reals = []\n",
    "\n",
    "    for i in range(1,6):\n",
    "        listaBoxes, listaDarknet = predictImage(path + str(i), False)\n",
    "        listaBoxesBuena = []\n",
    "        listaDarknetBuena = []\n",
    "        for j in listaBoxes:\n",
    "            listaBoxesBuena.append((j[0], j[1]))\n",
    "\n",
    "        for j in listaDarknet:\n",
    "            listaDarknetBuena.append((j[0], j[1]))\n",
    "\n",
    "        predicts.append(listaBoxesBuena)\n",
    "        reals.append(listaDarknetBuena)\n",
    "\n",
    "    predicts.sort()\n",
    "    reals.sort()\n",
    "\n",
    "    return predicts, reals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(path, tolerancia, tol_dist):\n",
    "    print(\"\\n\")\n",
    "    predicts, reals = get_predicts_and_reals(path)\n",
    "    \n",
    "    puntos_reales = []\n",
    "\n",
    "    for index, i in enumerate(reals[0]):\n",
    "        lista_separada = [sublista[index] for sublista in reals]\n",
    "        puntos_reales.append(lista_separada)\n",
    "    \n",
    "    results = postprocess_result(predicts, tolerancia, tol_dist)\n",
    "\n",
    "    print(\"PREDICTS:\")\n",
    "\n",
    "    for index, i in enumerate(results):\n",
    "        lista_limpia = [j[1] for j in i]\n",
    "        print(f\"Línea {index + 1}: {lista_limpia}\")\n",
    "\n",
    "    print(\"REALES:\")\n",
    "\n",
    "    for index, i in enumerate(puntos_reales):\n",
    "        print(f\"Línea {index + 1}: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Marc\\Desktop\\memoria-scripts\\train-memoria-ejemplos\\4\\1.png: 480x640 74.0ms\n",
      "Speed: 0.0ms pre-process, 74.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\Marc\\Desktop\\memoria-scripts\\train-memoria-ejemplos\\4\\2.png: 480x640 71.5ms\n",
      "Speed: 1.0ms pre-process, 71.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 C:\\Users\\Marc\\Desktop\\memoria-scripts\\train-memoria-ejemplos\\4\\3.png: 480x640 1 satellite, 74.5ms\n",
      "Speed: 0.0ms pre-process, 74.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\Marc\\Desktop\\memoria-scripts\\train-memoria-ejemplos\\4\\4.png: 480x640 1 satellite, 78.5ms\n",
      "Speed: 0.0ms pre-process, 78.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\Marc\\Desktop\\memoria-scripts\\train-memoria-ejemplos\\4\\5.png: 480x640 1 satellite, 74.5ms\n",
      "Speed: 0.0ms pre-process, 74.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTS:\n",
      "Línea 1: [(0.91, 0.66), (0.92, 0.69), (0.93, 0.71), (0.95, 0.76), (0.97, 0.82)]\n",
      "REALES:\n",
      "Línea 1: [(0.94, 0.7), (0.95, 0.76), (0.97, 0.82), (0.98, 0.87), (1.0, 0.93)]\n"
     ]
    }
   ],
   "source": [
    "path = \"C:/Users/Marc/Desktop/memoria-scripts/train-memoria-ejemplos/4/\"\n",
    "\n",
    "start(path, tolerancia=0.3, tol_dist=0.5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMvTR2EgvZclp1w7e8JmWGK",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0509cf87427649bab996b7a62679d471": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0b7256d19c18491ab7b3aa16b17a83c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "11c97c5338294fb2acfbcdb4114002c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1225e375719e4afe8fd53640b8d318dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16072c6cff6641b7943a02ff1eb345e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7d372136a56c4fd4976a5fcb56302ac2",
       "IPY_MODEL_33cb007fe18d4738bcb6099db18b8263",
       "IPY_MODEL_f386b01d70204da0b7776dcaef88aee4"
      ],
      "layout": "IPY_MODEL_11c97c5338294fb2acfbcdb4114002c6"
     }
    },
    "33cb007fe18d4738bcb6099db18b8263": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe98a854f8804182b2cd8a61653b7bab",
      "max": 6534387,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0b7256d19c18491ab7b3aa16b17a83c6",
      "value": 6534387
     }
    },
    "39d635c626ea4f7b874db5b6a0ddbff9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3a1410ccce2a42bc9170f402895cfdc0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "623f638458b64dc4a2b94c3ca99e91c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_adf4befc9db146f891407ff70fa8314d",
      "max": 773236,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7fca7e91a07548ddaf5c9953b8f28f25",
      "value": 773236
     }
    },
    "68c7ba0161fa426387f92fe9d7609f4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f85a96927f1340d8bca2d87664117c0b",
       "IPY_MODEL_623f638458b64dc4a2b94c3ca99e91c8",
       "IPY_MODEL_ad758fd580934ef190713468af5a9cb1"
      ],
      "layout": "IPY_MODEL_1225e375719e4afe8fd53640b8d318dc"
     }
    },
    "6a3e4f4d11df4dd2b58b5c86d5d80815": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d372136a56c4fd4976a5fcb56302ac2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_abb1ff860cd641d1905b036798edad44",
      "placeholder": "​",
      "style": "IPY_MODEL_0509cf87427649bab996b7a62679d471",
      "value": "100%"
     }
    },
    "7fca7e91a07548ddaf5c9953b8f28f25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "89b230048e224ba79aa359255f904a18": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "abb1ff860cd641d1905b036798edad44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad758fd580934ef190713468af5a9cb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbff4f37fc924fc080e70c59a664b1b1",
      "placeholder": "​",
      "style": "IPY_MODEL_6a3e4f4d11df4dd2b58b5c86d5d80815",
      "value": " 755k/755k [00:00&lt;00:00, 1.79MB/s]"
     }
    },
    "adf4befc9db146f891407ff70fa8314d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7483b8b5c02412d82158711c97c090e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbff4f37fc924fc080e70c59a664b1b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f386b01d70204da0b7776dcaef88aee4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a1410ccce2a42bc9170f402895cfdc0",
      "placeholder": "​",
      "style": "IPY_MODEL_39d635c626ea4f7b874db5b6a0ddbff9",
      "value": " 6.23M/6.23M [00:00&lt;00:00, 10.3MB/s]"
     }
    },
    "f85a96927f1340d8bca2d87664117c0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7483b8b5c02412d82158711c97c090e",
      "placeholder": "​",
      "style": "IPY_MODEL_89b230048e224ba79aa359255f904a18",
      "value": "100%"
     }
    },
    "fe98a854f8804182b2cd8a61653b7bab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
